package com.malwarebytes.kafka;

import com.fasterxml.jackson.annotation.JsonProperty;
import com.malwarebytes.kafka.deserializer.KafkaJsonDeserializer;
import com.malwarebytes.kafka.listener.KafkaConsumerListener;
import com.malwarebytes.kafka.model.CardInfo;
import io.dropwizard.jackson.Discoverable;
import io.dropwizard.lifecycle.Managed;
import io.dropwizard.setup.Environment;
import io.dropwizard.util.Duration;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import javax.validation.constraints.Min;
import javax.validation.constraints.NotEmpty;
import javax.validation.constraints.NotNull;
import java.util.Collections;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class KafkaConsumerCreatorFactory implements Runnable, Discoverable {
    KafkaConsumer<String, CardInfo> consumer;
    private KafkaConsumerListener<CardInfo> listener;

    @NotEmpty
    @JsonProperty
    protected String bootstrapServer;

    @NotEmpty
    @JsonProperty
    protected String topic;

    @NotEmpty
    @JsonProperty
    protected String consumerGroupId;

    @JsonProperty
    protected boolean autoCommitEnabled = true;

    @JsonProperty
    protected Duration autoCommitInterval = Duration.seconds(5);

    @Min(-1)
    @JsonProperty
    protected int sendBufferBytes = -1;

    @Min(-1)
    @JsonProperty
    protected int receiveBufferBytes = -1;

    @Min(1)
    @JsonProperty
    protected int maxPollRecords = 500;

    @NotNull
    @JsonProperty
    protected Duration maxPollInterval = Duration.minutes(5);
    public void create(){
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, consumerGroupId);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, autoCommitEnabled);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, (int)autoCommitInterval.toMilliseconds());
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, maxPollRecords);
        props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, (int)maxPollInterval.toMilliseconds());
        props.put(ConsumerConfig.SEND_BUFFER_CONFIG, sendBufferBytes);
        props.put(ConsumerConfig.RECEIVE_BUFFER_CONFIG, receiveBufferBytes);
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", KafkaJsonDeserializer.class.getName());
        consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList(topic));
    }

    public void build(
            Environment environment,
            KafkaConsumerListener<CardInfo> listener){
        this.listener = listener;
        create();
        environment.lifecycle().manage(new JobExecutionService());
    }

    @Override
    public void run() {
        while (true) {
            ConsumerRecords<String, CardInfo> records = consumer.poll(1000);
            for (ConsumerRecord<String, CardInfo> record : records) {
                System.out.printf("Consumer is working : offset = %d, key = %s, value = %s\n", record.offset(), record.key(), record.value());
                listener.consume(record.value());
            }
        }
    }

    class JobExecutionService implements Managed{
        private final ExecutorService service = Executors.newSingleThreadExecutor();

        @Override
        public void start() throws Exception {
            service.execute(KafkaConsumerCreatorFactory.this::run);
        }

        @Override
        public void stop() throws Exception {
            service.shutdown();
        }
    }
}
